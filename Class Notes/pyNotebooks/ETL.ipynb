{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "- What is it?\n",
    "- Types of ETL\n",
    "  -  Batch\n",
    "  -  Realtime\n",
    "\n",
    "\n",
    "## What is it?\n",
    "\n",
    "The bright future of decision making has been, and still is making decisions using data; not solely trusting human intuition.\n",
    "Analysts, scientists and statisticians have a problem, though. They want to understand data: but data is almost always inconsistent,\n",
    "corrupted, missing, or just plain invalid.\n",
    "\n",
    "That's because people are involved in data collection most of the time.\n",
    "\n",
    "However, as we hear over and over again: \n",
    "\n",
    "- \"You can have data without information, but you cannot have information without data.\" - Daniel Keys Moran\n",
    "\n",
    "The job of an Extraction Transformation and Loading (ETL) system is to try and homogenize those data into a consistent\n",
    "format so the data can be compared.\n",
    "\n",
    "It's much like a body's digestive system. It digests information into its constituent parts, orders what it can for use and \n",
    "discards the rest. As data engineers, you're the plumbers for your organization's GI tracts.\n",
    "\n",
    "### You're already practiced\n",
    "\n",
    "Already you know something about ETL. Even in your first classes you were loading data into the database using the `COPY FROM CSV` command.\n",
    "\n",
    "You were doing ETL there! Admittedly it was a very simple workflow -- most of the work was being doing in the database, but ETL is a continuum.\n",
    "\n",
    "\n",
    "### Extraction\n",
    "\n",
    "This is where we take information in one format and pull out the bits that are useful to our purpose.\n",
    "\n",
    "e.g. Pulling certain attributes out of a JSON object result from an API call.\n",
    "\n",
    "### Transformation\n",
    "\n",
    "Taking those extracted data, and putting them into whatever format we desire, correcting incorrect values where possible, possibly annotating related\n",
    "information into the same destination format.\n",
    "\n",
    "e.g. Putting the selected JSON attributes into a Protobuffer, adding identifier annotations to data in other systems.\n",
    "\n",
    "\n",
    "#### Loading\n",
    "\n",
    "Putting your data into a database for later analysis.\n",
    "\n",
    "e.g. psql -c \\COPY your_table FROM 'your_file.csv' CSV\n",
    "\n",
    "\n",
    "## Types of ETL\n",
    "\n",
    "### Batch\n",
    "\n",
    "This is in many ways the simplest way to construct a system, and how many of the highest performance ETL systems organize their work.\n",
    "\n",
    "One downside is that up-to-date information is only available after each batch is run.\n",
    "\n",
    "### Realtime\n",
    "\n",
    "This system means that you continuously update your database(s) as new information comes into your system. It's a good choice\n",
    "when the requirement is that your system's information must be close to real-time.\n",
    "\n",
    "One downside is that this is a more difficult system to scale as your data size and frequency increase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data Vars\n",
    "\n",
    "columns_headers = []\n",
    "num_rows = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Decorators\n",
    "\n",
    "def destroy_percent(percent, value):\n",
    "    \"\"\"Will corrupt, destoy or mangle a percentage of whatever data your wrapped function returns.\"\"\"\n",
    "    def decorator(func):\n",
    "        @wraps(func)\n",
    "        def _wrapped(*args, **kwargs):\n",
    "            ret_val = func(*args, **kwargs)\n",
    "            if isinstance(ret_val, collections.Iterable):\n",
    "                changed_values = {}\n",
    "                for idx, item in enumerate(ret_val):\n",
    "                    if random.randint(0, 100) < percent:\n",
    "                        changed_values[idx] = item\n",
    "                        \n",
    "                for change_idx, item in changed_values.items():\n",
    "                    if callable (value):\n",
    "                        ret_val[change_idx] = value(item)\n",
    "                    else:\n",
    "                        ret_val[change_idx] = value\n",
    "                    \n",
    "                return ret_val\n",
    "                        \n",
    "            # if we're a regular scalar, just replace our return value a random percent of the time.\n",
    "            if (random.randint(0, 100) < percent):\n",
    "                if callable(value):\n",
    "                    return value(ret_val)\n",
    "                return value\n",
    "            else:\n",
    "                return ret_val\n",
    "            \n",
    "        return _wrapped \n",
    "\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Finite Data\n",
    "states = ['OR', 'WA', 'CA', 'ID']\n",
    "state_initial_pops = {state : random.randint(10, 400) for state in states}\n",
    "BAD_CONTINUOUS_DATA_VALUES = [-1, None, 0, 45.3]\n",
    "\n",
    "def bad_data(*args, **kwargs):\n",
    "    return random.choice(BAD_CONTINUOUS_DATA_VALUES)\n",
    "\n",
    "def capitalize(input):\n",
    "    \"\"\"returns list of single letter that is captialized.\"\"\"\n",
    "    return [input.capitalize()]\n",
    "\n",
    "def insert_space(input):\n",
    "    \"\"\"returns list of a letter and a space character\"\"\"\n",
    "    return [input, ' ']\n",
    "\n",
    "string_transforms = [capitalize, insert_space]\n",
    "\n",
    "def randomize_string(input, percent=5):\n",
    "    output = []\n",
    "    letters = input.split()\n",
    "    for letter in input:\n",
    "        out_letter = [letter]\n",
    "        if random.randint(0, 100) < percent:\n",
    "            out_letter = random.choice(string_transforms)(letter)\n",
    "        output.extend(out_letter)\n",
    "        \n",
    "    return ''.join(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Continuous Data\n",
    "\n",
    "def get_population(mean, sigma, num_years):\n",
    "    return np.random.normal(mean, sigma, num_years)\n",
    "\n",
    "@destroy_percent(30, None)\n",
    "def get_pop_30_nan(current, sigma, num_years):\n",
    "    return get_population(current, sigma, num_years)\n",
    "\n",
    "@destroy_percent(50, bad_data)\n",
    "def get_pop_50_bad(current, sigma, num_years):\n",
    "    return get_population(current, sigma, num_years)\n",
    "\n",
    "def get_average_annual_income(current, sigma, num_years):\n",
    "    return np.random.normal(current, sigma, num_years)\n",
    "\n",
    "@destroy_percent(2, bad_data)\n",
    "def get_monthly_income(current, sigma, num_years):\n",
    "    return get_average_annual_income(current, sigma, num_years * 12)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_years = 4\n",
    "simple_data = [\n",
    "    {\n",
    "        'state': state,\n",
    "        'population': get_pop_50_bad(\n",
    "            state_initial_pops[state], random.randint(0, 40), num_years\n",
    "        ),\n",
    "        'income': get_average_annual_income(40, 7, num_years)\n",
    "    }\n",
    "    for state in states\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'income': array([ 44.15375771,  42.46976976,  42.59330565,  34.93537914]),\n",
       "  'population': array([  45.3       ,  240.02832273,  250.8050366 ,           nan]),\n",
       "  'state': 'OR'},\n",
       " {'income': array([ 34.41578499,  40.62633106,  44.45342219,  43.39362928]),\n",
       "  'population': array([ 343.9634566,   45.3      ,          nan,  324.5777359]),\n",
       "  'state': 'WA'},\n",
       " {'income': array([ 24.71569336,  42.31702963,  32.62325157,  47.5580181 ]),\n",
       "  'population': array([          nan,  328.71091114,  324.69037304,    0.        ]),\n",
       "  'state': 'CA'},\n",
       " {'income': array([ 42.96313886,  41.14147102,  52.21482124,  48.00284636]),\n",
       "  'population': array([   0.        ,  374.65407565,   -1.        ,  371.48091012]),\n",
       "  'state': 'ID'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     45.300000\n",
       "1    240.028323\n",
       "2    250.805037\n",
       "3           NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpolation of missing data\n",
    "# Sometimes this is pretty straight forward, esp. for missing data\n",
    "\n",
    "pandas.Series(simple_data[0]['population'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     45.300000\n",
       "1    240.028323\n",
       "2    250.805037\n",
       "3    250.805037\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.Series(simple_data[0]['population']).interpolate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Exercise\n",
    "## Build an ETL pipeline for our Simple Data\n",
    "\n",
    "def extract(uncleaned_data):\n",
    "    pass\n",
    "\n",
    "def transform(untransformed_data):\n",
    "    pass\n",
    "\n",
    "def load(unloaded_data):\n",
    "    \"\"\"Here let's just return a format that can be converted into a CSV with headers easily,\n",
    "    a list of dictionaries would do nicely.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advanced_data = [\n",
    "    {\n",
    "        randomize_string('state', 50): randomize_string(state),\n",
    "        randomize_string('population', 25): get_pop_50_bad(\n",
    "            state_initial_pops[state], random.randint(0, 40), num_years\n",
    "        ),\n",
    "        randomize_string('income', 40): get_average_annual_income(40, 7, num_years)\n",
    "    }\n",
    "    for state in states\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'iNcome': array([ 27.48434952,  32.97035589,  26.82094304,  51.45420639]),\n",
       "  'popu latio n': array([  -1.       ,   45.3      ,  218.2871671,          nan]),\n",
       "  'st ate': 'OR'},\n",
       " {'income': array([ 38.47283945,  42.45225343,  30.91099613,  34.70738569]),\n",
       "  'populAtion ': array([ 368.90184878,    0.        ,   -1.        ,  365.1133105 ]),\n",
       "  's taTE': 'WA'},\n",
       " {'iNc oME': array([ 36.85357938,  37.00056181,  43.07557702,  36.09485356]),\n",
       "  'po pulation': array([          nan,   -1.        ,  348.33769686,           nan]),\n",
       "  'sta te': 'CA'},\n",
       " {'in Co Me ': array([ 36.04575008,  33.19909722,  32.01395239,  38.83888557]),\n",
       "  'poPu la tion': array([   0.        ,           nan,  340.06933955,  353.046158  ]),\n",
       "  's TatE': 'ID'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalizing Strings\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "all_column_names = [sorted(item.keys()) for item in advanced_data]\n",
    "first_column_names = [item[0] for item in all_column_names]\n",
    "\n",
    "def get_column_similarities(list_of_columns):\n",
    "    ratios = []\n",
    "    for name in list_of_columns:\n",
    "        # Going through our list of column_names and comparing it with the next one in the list.\n",
    "        if list_of_columns.index(name) + 1 < len(list_of_columns):\n",
    "            ratios.append((name, SequenceMatcher(\n",
    "                        None, name, list_of_columns[list_of_columns.index(name) + 1]\n",
    "                    ).ratio()))\n",
    "        else:\n",
    "            ratios.append((name, 0.0))\n",
    "    return ratios\n",
    "\n",
    "my_ratios = get_column_similarities(first_column_names)\n",
    "un_sorted = get_column_similarities([item.keys()[0] for item in advanced_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('iNcome', 0.8333333333333334),\n",
       " ('income', 0.46153846153846156),\n",
       " ('iNc oME', 0.5),\n",
       " ('in Co Me ', 0.0)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('st ate', 0.5),\n",
       " ('s taTE', 0.23529411764705882),\n",
       " ('po pulation', 0.782608695652174),\n",
       " ('poPu la tion', 0.0)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###Exercise\n",
    "## Build and ETL pipleine for our Advanced Data\n",
    "\n",
    "def extract(uncleaned_data):\n",
    "    pass\n",
    "\n",
    "def transform(untransformed_data):\n",
    "    pass\n",
    "\n",
    "def load(unloaded_data):\n",
    "    \"\"\"Here let's just return a format that can be converted into a CSV with headers easily,\n",
    "    a list of dictionaries would do nicely.\n",
    "    \"\"\"\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
